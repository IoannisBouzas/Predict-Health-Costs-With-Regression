# -*- coding: utf-8 -*-
"""Predict_Health_Costs_With_Regression_FCC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IJc_f7B9bptaYrp08uAc8TPVnxYcaabT
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries. You may or may not use all of these.
!pip install -q git+https://github.com/tensorflow/docs
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from tensorflow import keras
from keras import layers

import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

# Import data
!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv
dataset = pd.read_csv('insurance.csv')
dataset.tail()

#Convert categorical sex values into numeric
label_encoder = LabelEncoder()
dataset['sex'] = label_encoder.fit_transform(dataset['sex']) #0 for female and 1 for male

# Define the mapping
smoker_mapping = {'no': 0, 'yes': 1}

# Map the values
dataset['smoker'] = dataset['smoker'].map(smoker_mapping)


#Convert categorical region values into numeric
region_mapping = {'southwest' : 0, 'northwest' : 1, 'northeast' : 2, 'southeast' : 3}

dataset['region'] = dataset['region'].map(region_mapping)

print(dataset.head())

test_dataset = dataset.sample(frac=0.2) #pick random 20% of the rows to make the test_dataset, 280 rows

train_dataset = dataset.drop(test_dataset.index) #pick the remaining 80% of rows to make the train_dataset, 1070 rows

#Prepare the labels
train_labels = train_dataset.pop('expenses')

test_labels = test_dataset.pop('expenses')

#Build the Model

#First we normalize to make the training more stable
normalizer = tf.keras.layers.Normalization()
normalizer.adapt(np.array(train_dataset))

#Calculate the mean and variance:
print(normalizer.mean.numpy())

model = keras.Sequential([
      normalizer,
      layers.Dense(64, activation='relu'),
      layers.Dense(64, activation='relu'),
      layers.Dense(1)
  ])

model.compile(loss='mae',
              metrics=['mae', 'mse'],
              optimizer=tf.keras.optimizers.Adam(0.001))

model.build()
model.summary()

#Feed the model
history = model.fit(
    train_dataset,
    train_labels,
    validation_split=0.5,
    verbose=0, epochs=100)

# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.
# Test model by checking how well the model generalizes using the test set.
loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} expenses".format(mae))

if mae < 3500:
  print("You passed the challenge. Great job!")
else:
  print("The Mean Abs Error must be less than 3500. Keep trying.")

# Plot predictions.
test_predictions = model.predict(test_dataset).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_labels, test_predictions)
plt.xlabel('True values (expenses)')
plt.ylabel('Predictions (expenses)')
lims = [0, 50000]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims,lims)